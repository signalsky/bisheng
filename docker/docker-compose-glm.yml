version: '3.8'

services:
  glm-4-9b-chat:
    image: vllm/vllm-openai:v0.8.4
    container_name: glm-4-9b-chat
    restart: always
    ports:
      - "9010:8000"
    volumes:
      - ${DOCKER_VOLUME_DIRECTORY:-.}/models/glm-4-9b-chat/:/mnt/model/
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    command: >
      --served-model-name glm-4-9b-chat
      --model="/mnt/model/"
      --task generate
      --gpu-memory-utilization 0.6
      --tensor-parallel-size 1
      --api-key vllm
      --trust-remote-code
      --dtype=half

